{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "#from random import randrange\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image helper ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (2,1,0)))\n",
    "    plt.show()\n",
    "def get_image(i_dim, n_dim, n_pos, n_strength, pos_scale):\n",
    "    image = torch.zeros((3, i_dim,i_dim), requires_grad=False)\n",
    "    if isinstance(n_pos, torch.Tensor):\n",
    "        #n_pos *= pos_scale\n",
    "        i_n_pos = torch.clamp(torch.round(n_pos * pos_scale).type(torch.int), min=0, max=i_dim-n_dim)\n",
    "    else:\n",
    "        i_n_pos = np.round(n_pos * pos_scale).astype(int).clip(0,i_dim-n_dim)\n",
    "    #print(i_n_pos)\n",
    "    for c in range(3): #to get it equal over all chanels \n",
    "        image[c, i_n_pos[0].item():(i_n_pos[0].item() + n_dim),i_n_pos[1].item():(i_n_pos[1].item()+n_dim)] = n_strength\n",
    "    return image\n",
    "def net_show(input_label, n_pos, n_strength=torch.ones((3,3)), pos_scale=62):\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(n_pos)):\n",
    "            #get the guess\n",
    "            npn_pos = n_pos[i].numpy()\n",
    "            image = get_image(i_dim, n_dim, npn_pos, n_strength, pos_scale)\n",
    "            image[1:3,:,:] = 0.0 #make the guess red\n",
    "            #get the correct image\n",
    "            label = input_label[i].numpy()\n",
    "            npn_image = get_image(i_dim, n_dim, label, n_strength, pos_scale)\n",
    "            #add them (clip) and show\n",
    "            image = np.maximum(image, npn_image)\n",
    "            image_show(image)\n",
    "            #write information\n",
    "            coord_l = np.round(label * pos_scale)\n",
    "            coord_n = np.round(npn_pos * pos_scale)\n",
    "            print(f\"Loss: {loss_fn(input_label[i], n_pos[i])}, x_l = {coord_l[0]}, y_l = {coord_l[1]}, x_t = {coord_n[0]}, y_t = {coord_n[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_dim = 32\n",
    "n_dim = 3\n",
    "\n",
    "dataset_parameter = {\n",
    "    \"train\": (\"./pixel_finder_train_data.pth\", 2000), \n",
    "    \"test\": (\"./pixel_finder_test_data.pth\", 500),\n",
    "    \"validate\": (\"./pixel_finder_validate_data.pth\",500)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePositionDataset(Dataset):\n",
    "    def __init__(self, i_dim, n_dim, sample_size, path=\"\"):\n",
    "        self.i_dim = i_dim\n",
    "        self.n_dim = n_dim\n",
    "        self.pos_scale = i_dim-n_dim #changed from -1, because of rounding\n",
    "        if path != \"\": #load the data\n",
    "            self.load(path, i_dim, n_dim)\n",
    "            assert sample_size == self.sample_size\n",
    "        else: #create new data\n",
    "            self.sample_size = sample_size\n",
    "            self.data = []\n",
    "            for i in range(sample_size):\n",
    "                n_pos = torch.flatten(torch.rand((1,2)))\n",
    "                n_strength = torch.rand((3,3))#np.random.rand(n_dim, n_dim) #one chanel\n",
    "                self.data.append((n_pos, n_strength))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sample_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = (get_image(i_dim, n_dim, self.data[idx][0], self.data[idx][1], self.pos_scale), self.data[idx][0], self.pos_scale)\n",
    "        return sample\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.data, path)\n",
    "        \n",
    "    def load(self, path, i_dim, n_dim):\n",
    "        self.data = torch.load(path)\n",
    "        self.sample_size = len(self.data)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset\n",
    "dataset = {}\n",
    "dataloader = {}\n",
    "for name, parameter in dataset_parameter.items():\n",
    "    dataset[name] = ImagePositionDataset(i_dim, n_dim, parameter[1])\n",
    "    dataset[name].save(parameter[0])\n",
    "    dataloader[name] = DataLoader(dataset[name], batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataloader = {}\n",
    "for name, parameter in dataset_parameter.items():\n",
    "    dataset[name] = ImagePositionDataset(i_dim, n_dim, parameter[1], path=parameter[0])\n",
    "    dataloader[name] = DataLoader(dataset[name], batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(dataloader[\"test\"])\n",
    "images, labels, scales = dataiter.next()\n",
    "image_show(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,_,_ = dataset[\"test\"][0]\n",
    "image_show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test net on selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09293408691883087, x_l = 27.0, y_l = 20.0, x_t = 35.0, y_t = 25.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0011804697569459677, x_l = 14.0, y_l = 8.0, x_t = 13.0, y_t = 7.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.002943632658571005, x_l = 4.0, y_l = 12.0, x_t = 3.0, y_t = 12.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.006067774724215269, x_l = 1.0, y_l = 12.0, x_t = -1.0, y_t = 11.0.\n"
     ]
    }
   ],
   "source": [
    "outputs = net[net_choice](images) \n",
    "#net(image.unsqueeze(0));\n",
    "net_show(labels, outputs,pos_scale=i_dim-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9438, 0.6781])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = {}\n",
    "net = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetPath(net_choice, epoch, learnrate, original=False):\n",
    "    if original:\n",
    "        return f\"{net_path[net_choice]}.pth\"\n",
    "    return f\"{net_path[net_choice]}_lr_{learnrate}_ep_{epoch}.pth\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"conv\"] = './pixel_finder_conv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "\n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
    "\n",
    "def activation_func(activation):\n",
    "    return  nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    \n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "    \n",
    "    \n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    \"\"\"\n",
    "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )\n",
    "    \n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "class ResNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet layer composed by `n` blocks stacked one after the other\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = ResNetLayer(3, 16, block=ResNetBasicBlock, n=2)\n",
    "        self.fc1 = nn.Linear(32*32*16 , 1024)\n",
    "        self.fc2 = nn.Linear(1024,2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sig(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "net[\"conv\"] = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"linear\"] = './pixel_finder_linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(i_dim*i_dim*3, i_dim*i_dim*3)\n",
    "        self.fc2 = nn.Linear(i_dim*i_dim*3,2)\n",
    "        #self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net[\"linear\"] = LinearNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"linearSig\"] = './pixel_finder_linear_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSigNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearSigNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(i_dim*i_dim*3, i_dim*i_dim*3)\n",
    "        self.fc2 = nn.Linear(i_dim*i_dim*3,2)\n",
    "        #self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.Sigmoid(x)\n",
    "\n",
    "\n",
    "net[\"linearSig\"] = LinearSigNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_choice = \"linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {\n",
    "    \"learnrate\" : (0.01,0.001),\n",
    "    \"epoch\" : (4,6)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "learnrate = 0.00001\n",
    "epoch = 3\n",
    "hyperparameter = {\n",
    "    \"learnrate\" : (learnrate,),\n",
    "    \"epoch\" : (epoch,)}\n",
    "\n",
    "net_choice = \"linear\"\n",
    "optimizer[learnrate] = torch.optim.Adam(net[net_choice].parameters(), lr=learnrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, optimization criterion, optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = {}\n",
    "for lr in hyperparameter[\"learnrate\"]:\n",
    "    optimizer[lr] = torch.optim.Adam(net[net_choice].parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output every running_loss_count\n",
    "running_loss_count = 50\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate the net with 3 epochs and a learning rate of 1e-05\n",
      "(Epoch 1, batch 50): 0.0006277454062364996\n",
      "(Epoch 1, batch 100): 0.0013803709468629677\n",
      "(Epoch 1, batch 150): 0.0007565843540942297\n",
      "(Epoch 1, batch 200): 0.0008001771193812601\n",
      "(Epoch 1, batch 250): 0.0006707809127692599\n",
      "(Epoch 1, batch 300): 0.0007458116406633053\n",
      "(Epoch 1, batch 350): 0.0013164694170700387\n",
      "(Epoch 1, batch 400): 0.0008164458876854042\n",
      "(Epoch 1, batch 450): 0.0011113643627322744\n",
      "(Epoch 1, batch 500): 0.0008408850996056571\n",
      "(Epoch 2, batch 50): 0.0006217041649870226\n",
      "(Epoch 2, batch 100): 0.0008104765971074812\n",
      "(Epoch 2, batch 150): 0.000769969752363977\n",
      "(Epoch 2, batch 200): 0.0009189678014081438\n",
      "(Epoch 2, batch 250): 0.0007409313096286497\n",
      "(Epoch 2, batch 300): 0.0007753830916772131\n",
      "(Epoch 2, batch 350): 0.0010209543002565624\n",
      "(Epoch 2, batch 400): 0.000986279423814267\n",
      "(Epoch 2, batch 450): 0.0009219195594778284\n",
      "(Epoch 2, batch 500): 0.0006347766803082777\n",
      "(Epoch 3, batch 50): 0.000843994386959821\n",
      "(Epoch 3, batch 100): 0.0010130142194248036\n",
      "(Epoch 3, batch 150): 0.0009114923371816985\n",
      "(Epoch 3, batch 200): 0.0006507460538705346\n",
      "(Epoch 3, batch 250): 0.0006582715055992594\n",
      "(Epoch 3, batch 300): 0.000580027322503156\n",
      "(Epoch 3, batch 350): 0.0007926035988202784\n",
      "(Epoch 3, batch 400): 0.0007012395700439811\n",
      "(Epoch 3, batch 450): 0.0008165250513047795\n",
      "(Epoch 3, batch 500): 0.0006868924396985676\n",
      "(Batch 50): 0.026015209073666484\n",
      "(Batch 100): 0.022267879680730403\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# save starting net\n",
    "torch.save(net[net_choice].state_dict(), getNetPath(net_choice, 0,0, original=True))\n",
    "\n",
    "for num_epoch in hyperparameter[\"epoch\"]:\n",
    "    for learnrate in hyperparameter[\"learnrate\"]:\n",
    "        #load the original net to start from the same parameters\n",
    "        net[net_choice].load_state_dict(torch.load(getNetPath(net_choice, 0,0, original=True)))\n",
    "        net[net_choice].train()\n",
    "        metrics[(num_epoch, learnrate, \"running_loss\")] = []\n",
    "        metrics[(num_epoch, learnrate, \"validation_loss\")] = []\n",
    "        print(f\"Calculate the net with {num_epoch} epochs and a learning rate of {learnrate}\")\n",
    "        for epoch in range(num_epoch):\n",
    "            loss_running = 0.0\n",
    "            for i_batch, sample_batched in enumerate(dataloader[\"train\"]):\n",
    "                inputs, labels, _ = sample_batched\n",
    "                \n",
    "                #reset calculated gradients\n",
    "                optimizer[learnrate].zero_grad()\n",
    "                \n",
    "                #calculate the output and loss\n",
    "                outputs = net[net_choice](inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                #backpropagate loss and optimize parameter\n",
    "                loss.backward()\n",
    "                optimizer[learnrate].step()\n",
    "                \n",
    "                #track loss\n",
    "                loss_running += loss.item()\n",
    "                if i_batch % running_loss_count == running_loss_count -1:\n",
    "                    print(f\"(Epoch {epoch + 1}, batch {i_batch + 1}): {loss_running/running_loss_count}\")\n",
    "                    metrics[(num_epoch, learnrate, \"running_loss\")].append(loss_running)\n",
    "                    loss_running = 0.0\n",
    "            #save the trained net after each epoch\n",
    "            torch.save({\"net_state_dict\":net[net_choice].state_dict(),\n",
    "                   \"optimizer_state_dict\":optimizer[learnrate].state_dict(),\n",
    "                   \"epoch\" : epoch}, getNetPath(net_choice, epoch,learnrate))\n",
    "        #torch.save(net[net_choice].state_dict(), getNetPath(net_choice, epoch,learnrate))\n",
    "        \n",
    "        #do the validation\n",
    "        net[net_choice].eval()\n",
    "        with torch.no_grad():\n",
    "            loss_running = 0.0\n",
    "            for i_batch, sample_batched in enumerate(dataloader[\"validate\"]):\n",
    "                inputs, labels, _ = sample_batched\n",
    "                \n",
    "                #calculate the output and loss\n",
    "                outputs = net[net_choice](inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                #track loss\n",
    "                loss_running += loss.item()\n",
    "                if i_batch % running_loss_count == running_loss_count -1:\n",
    "                    print(f\"(Batch {i_batch + 1}): {loss_running/running_loss_count}\")\n",
    "                    metrics[(num_epoch, learnrate, \"validation_loss\")].append(loss_running)\n",
    "                    loss_running = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the net as basis for the next round\n",
    "torch.save(net[net_choice].state_dict(), getNetPath(net_choice, 0,0, original=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "learnrate = 0.0001\n",
    "epoch = 3\n",
    "hyperparameter = {\n",
    "    \"learnrate\" : (learnrate,),\n",
    "    \"epoch\" : (epoch,)}\n",
    "\n",
    "net_choice = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pixel_finder_linear_lr_0.0005_ep_2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-0740ffbe768b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetNetPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_choice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearnrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlearnrate\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet_choice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearnrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlearnrate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"optimizer_state_dict\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pixel_finder_linear_lr_0.0005_ep_2.pth'"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = {}\n",
    "checkpoint = torch.load(getNetPath(net_choice, epoch, learnrate))\n",
    "optimizer[learnrate] = torch.optim.Adam(net[net_choice].parameters(), lr=learnrate)\n",
    "optimizer[learnrate].load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "net[net_choice].load_state_dict(checkpoint[\"net_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, learnrate, dataset, loss in metrics.items():\n",
    "    if dataset == \"validation_loss\":\n",
    "        plt.plot(range(len(loss))*running_loss_count, loss,label=f\"lr: {learnrate}, epochs:{epochs}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
