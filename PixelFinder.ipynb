{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "#from random import randrange\n",
    "import cv2 \n",
    "from torchsummary import summary #pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image helper ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (2,1,0)))\n",
    "    plt.show()\n",
    "def get_image(i_dim, n_dim, n_pos, n_strength, pos_scale):\n",
    "    image = torch.zeros((3, i_dim,i_dim), requires_grad=False)\n",
    "    if isinstance(n_pos, torch.Tensor):\n",
    "        #n_pos *= pos_scale\n",
    "        i_n_pos = torch.clamp(torch.round(n_pos * pos_scale).type(torch.int), min=0, max=i_dim-n_dim)\n",
    "    else:\n",
    "        i_n_pos = np.round(n_pos * pos_scale).astype(int).clip(0,i_dim-n_dim)\n",
    "    #print(i_n_pos)\n",
    "    for c in range(3): #to get it equal over all chanels \n",
    "        image[c, i_n_pos[0].item():(i_n_pos[0].item() + n_dim),i_n_pos[1].item():(i_n_pos[1].item()+n_dim)] = n_strength\n",
    "    return image\n",
    "def net_show(input_label, n_pos, n_strength=torch.ones((3,3)), pos_scale=62):\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(n_pos)):\n",
    "            #get the guess\n",
    "            npn_pos = n_pos[i].numpy()\n",
    "            image = get_image(i_dim, n_dim, npn_pos, n_strength, pos_scale)\n",
    "            image[1:3,:,:] = 0.0 #make the guess red\n",
    "            #get the correct image\n",
    "            label = input_label[i].numpy()\n",
    "            npn_image = get_image(i_dim, n_dim, label, n_strength, pos_scale)\n",
    "            #add them (clip) and show\n",
    "            image = np.maximum(image, npn_image)\n",
    "            image_show(image)\n",
    "            #write information\n",
    "            coord_l = np.round(label * pos_scale)\n",
    "            coord_n = np.round(npn_pos * pos_scale)\n",
    "            print(f\"Loss: {loss_fn(input_label[i], n_pos[i])}, x_l = {coord_l[0]}, y_l = {coord_l[1]}, x_t = {coord_n[0]}, y_t = {coord_n[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_dim = 32\n",
    "n_dim = 3\n",
    "\n",
    "dataset_parameter = {\n",
    "    \"train\": (\"./pixel_finder_train_data.pth\", 2000), \n",
    "    \"test\": (\"./pixel_finder_test_data.pth\", 500),\n",
    "    \"validate\": (\"./pixel_finder_validate_data.pth\",500)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePositionDataset(Dataset):\n",
    "    def __init__(self, i_dim, n_dim, sample_size, path=\"\"):\n",
    "        self.i_dim = i_dim\n",
    "        self.n_dim = n_dim\n",
    "        self.pos_scale = i_dim-n_dim #changed from -1, because of rounding\n",
    "        if path != \"\": #load the data\n",
    "            self.load(path, i_dim, n_dim)\n",
    "            assert sample_size == self.sample_size\n",
    "        else: #create new data\n",
    "            self.sample_size = sample_size\n",
    "            self.data = []\n",
    "            for i in range(sample_size):\n",
    "                n_pos = torch.flatten(torch.rand((1,2)))\n",
    "                n_strength = torch.rand((3,3))#np.random.rand(n_dim, n_dim) #one chanel\n",
    "                n_pos *= self.pos_scale\n",
    "                n_pos = torch.clamp(torch.round(n_pos),min=0,max=i_dim-n_dim)\n",
    "                n_pos /= self.pos_scale\n",
    "                self.data.append((n_pos, n_strength))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sample_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = (get_image(i_dim, n_dim, self.data[idx][0], self.data[idx][1], self.pos_scale), self.data[idx][0], self.pos_scale)\n",
    "        return sample\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.data, path)\n",
    "        \n",
    "    def load(self, path, i_dim, n_dim):\n",
    "        self.data = torch.load(path)\n",
    "        self.sample_size = len(self.data)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset\n",
    "dataset = {}\n",
    "dataloader = {}\n",
    "for name, parameter in dataset_parameter.items():\n",
    "    dataset[name] = ImagePositionDataset(i_dim, n_dim, parameter[1])\n",
    "    dataset[name].save(parameter[0])\n",
    "    dataloader[name] = DataLoader(dataset[name], batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataloader = {}\n",
    "for name, parameter in dataset_parameter.items():\n",
    "    dataset[name] = ImagePositionDataset(i_dim, n_dim, parameter[1], path=parameter[0])\n",
    "    dataloader[name] = DataLoader(dataset[name], batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(dataloader[\"train\"])\n",
    "images, labels, scales = dataiter.next()\n",
    "image_show(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,_,_ = dataset[\"validate\"][0]\n",
    "image_show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test net on selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.005425386596471071, x_l = 24.0, y_l = 7.0, x_t = 26.0, y_t = 6.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00017682100587990135, x_l = 11.0, y_l = 10.0, x_t = 10.0, y_t = 10.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALUUlEQVR4nO3dUahl5XnG8f9To7SoUI1VBh1rIlIIEkYRKUSChTZMvVELluRqCoWTiwp6UYik0Nhe2RItvRJslQylNQg2VaTUiBhMb6yjHXXsJNEEa0YHhzAU9SpNfHux18BxOuec7d5r7X30/f9gs9f+ztprvXycZ69vrX3O+lJVSPrk+5V1FyBpNQy71IRhl5ow7FIThl1qwrBLTXxqmTcn2Q/8LXAW8PdVdc8O6/s9nzSxqsqZ2rPo9+xJzgJ+BPwecAx4HvhKVf3XNu8x7NLEtgr7MsP464HXq+onVfVz4NvAzUtsT9KElgn7pcBPN70+NrRJ2oWWOWc/01Dh/w3Tk2wAG0vsR9IIlgn7MWDvpteXAW+fvlJVPQA8AJ6zS+u0zDD+eeCqJJ9Jcg7wZeDxccqSNLaFj+xV9YsktwNPMvvq7aGqenW0yiSNauGv3hbamcN4aXJTfPUm6WPEsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWpimYkdSfIG8B7wS+AXVXXdGEVJGt9SYR/8TlX9bITtSJqQw3ipiWXDXsB3k7yQZGOMgiRNY9lh/Beq6u0kFwNPJflBVT27eYXhQ8APAmnNRpuyOcndwPtV9c1t1nHKZmlio0/ZnOTcJOefWga+BBxZdHuSprXMMP4S4DtJTm3nn6rq30apStLoRhvGz7Uzh/HS5EYfxkv6eDHsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmtgx7EkeSnIiyZFNbRcmeSrJa8PzBdOWKWlZ8xzZvwXsP63tLuDpqroKeHp4LWkX2zHsw3zrJ09rvhk4OCwfBG4ZuS5JI1v0nP2SqjoOMDxfPF5JkqawzJTNc0myAWxMvR9J21v0yP5Okj0Aw/OJrVasqgeq6rqqum7BfUkawaJhfxw4MCwfAB4bpxxJU0lVbb9C8jBwI3AR8A7wDeBfgEeAy4E3gduq6vSLeGfa1vY7k7S0qsqZ2ncM+5gMuzS9rcLuX9BJTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYmv3mFdocp/uEpOeP/W2iX8sguNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5rYMexJHkpyIsmRTW13J3kryeHhcdO0ZUpa1jxH9m8B+8/Q/jdVtW94/Ou4ZUka245hr6pngR0nbZS0uy1zzn57kpeHYf4Fo1UkaRKLhv1+4EpgH3AcuHerFZNsJDmU5NCC+5I0grmmbE5yBfBEVV39UX52hnWdsnlNvFNNH6NO2Zxkz6aXtwJHtlpX0u6w4z3okjwM3AhclOQY8A3gxiT7gALeAL46YY0agUdhzTWMH21nDuOlyY06jJf08WPYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNbFj2JPsTfJMkqNJXk1yx9B+YZKnkrw2PDtts7SL7Tj90zCJ456qejHJ+cALwC3AHwEnq+qeJHcBF1TV13bYltM/SRNbePqnqjpeVS8Oy+8BR4FLgZuBg8NqB5l9AEjapT7SOfswF/s1wHPAJVV1HGYfCMDFYxcnaTw7Ttl8SpLzgEeBO6vq3XmnAE6yAWwsVp6kscw1ZXOSs4EngCer6r6h7YfAjVV1fDiv/15V/dYO2/GcXZrYwufsmR3CHwSOngr64HHgwLB8AHhs2SIlTWeeq/E3AN8HXgE+GJq/zuy8/RHgcuBN4LaqOrnDtjyySxPb6sg+1zB+LIZdmt7Cw3hJnwyGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPzzPW2N8kzSY4meTXJHUP73UneSnJ4eNw0fbmSFjXPXG97gD1V9WKS84EXgFuAPwTer6pvzr0zp3+SJrfV9E87zs9eVceB48Pye0mOApeOW56kqX2kc/YkVwDXMJvBFeD2JC8neSjJBSPXJmlEc4c9yXnAo8CdVfUucD9wJbCP2ZH/3i3et5HkUJJDI9QraUFzTdmc5GzgCeDJqrrvDD+/Aniiqq7eYTues0sTW3jK5iQBHgSObg76cOHulFuBI8sWKWk681yNvwH4PvAK8MHQ/HXgK8yG8AW8AXx1uJi33bY8sksT2+rIPtcwfiyGXZrewsN4SZ8Mhl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIT88z19qtJ/iPJS0leTfIXQ/uFSZ5K8trw7JTN0i42z1xvAc6tqveH2Vz/HbgD+APgZFXdk+Qu4IKq+toO23L6J2liC0//VDPvDy/PHh4F3AwcHNoPAreMUKekicx1zp7krCSHgRPAU1X1HHDJqVlbh+eLpytT0rLmCntV/bKq9gGXAdcnuXreHSTZSHIoyaFFi5S0vI90Nb6q/gf4HrAfeCfJHoDh+cQW73mgqq6rquuWrFXSEua5Gv8bSX59WP414HeBHwCPAweG1Q4Aj01VpKTlzXM1/vPMLsCdxezD4ZGq+ssknwYeAS4H3gRuq6qTO2zLq/HSxLa6Gr9j2Mdk2KXpLfzVm6RPBsMuNWHYpSYMu9SEYZea+NSK9/cz4L+H5YuG1+tmHR9mHR/2cavjN7f6wUq/evvQjpNDu+Gv6qzDOrrU4TBeasKwS02sM+wPrHHfm1nHh1nHh31i6ljbObuk1XIYLzWxlrAn2Z/kh0leH+5ftxZJ3kjySpLDq7y5RpKHkpxIcmRT28pv4LlFHXcneWvok8NJblpBHXuTPJPk6HBT0zuG9pX2yTZ1rLRPJrvJa1Wt9MHsX2V/DHwWOAd4CfjcqusYankDuGgN+/0icC1wZFPbXwN3Dct3AX+1pjruBv50xf2xB7h2WD4f+BHwuVX3yTZ1rLRPgADnDctnA88Bv71sf6zjyH498HpV/aSqfg58m9nNK9uoqmeB0//3f+U38NyijpWrquNV9eKw/B5wFLiUFffJNnWsVM2MfpPXdYT9UuCnm14fYw0dOijgu0leSLKxphpO2U038Lw9ycvDMH+l8wEkuQK4htnRbG19clodsOI+meImr+sI+5n+sX5dXwl8oaquBX4f+JMkX1xTHbvJ/cCVwD7gOHDvqnac5DzgUeDOqnp3Vfudo46V90ktcZPXrawj7MeAvZteXwa8vYY6qKq3h+cTwHeYnWKsy1w38JxaVb0z/KJ9APwdK+qTYQKSR4F/rKp/HppX3idnqmNdfTLs+yPf5HUr6wj788BVST6T5Bzgy8xuXrlSSc5Ncv6pZeBLwJHt3zWpXXEDz1O/TINbWUGfDLMOPQgcrar7Nv1opX2yVR2r7pPJbvK6qiuMp11tvInZlc4fA3+2pho+y+ybgJeAV1dZB/Aws+Hg/zIb6fwx8GngaeC14fnCNdXxD8ArwMvDL9eeFdRxA7NTuZeBw8PjplX3yTZ1rLRPgM8D/zns7wjw50P7Uv3hX9BJTfgXdFIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmvg/2dAiaK7vt4sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004358791629783809, x_l = 14.0, y_l = 13.0, x_t = 14.0, y_t = 13.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALXUlEQVR4nO3dX6hl5XnH8e+vRmlRoRqrDP6piUghSBhFpBAJFtpgvVELluRqCoWTiwp6UYik0Nhe2RItvRJslQylNQg2VaTUiBhMb6yjHXXsJNEEa0YHhyBFvUoTn17sNXCcnj/bvdfa+zjP9wObvfZ71l7r4eX89nrX2uesN1WFpNPfr6y7AEmrYdilJgy71IRhl5ow7FIThl1q4lPLvDnJjcDfAmcAf19V9+yyvt/zSROrqmzVnkW/Z09yBvAj4PeAY8DzwFeq6r92eI9hlya2XdiXGcZfB7xeVT+pqp8D3wZuXmJ7kia0TNgvBn666fWxoU3SHrTMOftWQ4X/N0xPsgFsLLEfSSNYJuzHgEs3vb4EePvUlarqAeAB8JxdWqdlhvHPA1cm+UySs4AvA4+PU5aksS18ZK+qXyS5HXiS2VdvD1XVq6NVJmlUC3/1ttDOHMZLk5viqzdJnyCGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPLTOxIkjeA94FfAr+oqmvHKErS+JYK++B3qupnI2xH0oQcxktNLBv2Ar6b5IUkG2MUJGkayw7jv1BVbye5EHgqyQ+q6tnNKwwfAn4QSGs22pTNSe4GPqiqb+6wjlM2SxMbfcrmJGcnOffkMvAl4Mii25M0rWWG8RcB30lycjv/VFX/NkpVkkY32jB+rp05jJcmN/owXtIni2GXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUxK5hT/JQkhNJjmxqOz/JU0leG57Pm7ZMScua58j+LeDGU9ruAp6uqiuBp4fXkvawXcM+zLf+7inNNwMHh+WDwC0j1yVpZIues19UVccBhucLxytJ0hSWmbJ5Lkk2gI2p9yNpZ4se2d9Jsg9geD6x3YpV9UBVXVtV1y64L0kjWDTsjwMHhuUDwGPjlCNpKqmqnVdIHgZuAC4A3gG+AfwL8AhwGfAmcFtVnXoRb6tt7bwzSUurqmzVvmvYx2TYpeltF3b/gk5qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qYtewJ3koyYkkRza13Z3krSSHh8dN05YpaVnzHNm/Bdy4RfvfVNX+4fGv45YlaWy7hr2qngV2nbRR0t62zDn77UleHob5541WkaRJLBr2+4ErgP3AceDe7VZMspHkUJJDC+5L0gjmmrI5yeXAE1V11cf52RbrOmWzNLFRp2xOsm/Ty1uBI9utK2lv+NRuKyR5GLgBuCDJMeAbwA1J9gMFvAF8dcIaJY1grmH8aDtzGC9NbtRhvKRPHsMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapiV3DnuTSJM8kOZrk1SR3DO3nJ3kqyWvDs9M2S3vYrtM/DZM47quqF5OcC7wA3AL8EfBuVd2T5C7gvKr62i7bcvonaWILT/9UVcer6sVh+X3gKHAxcDNwcFjtILMPAEl71Mc6Zx/mYr8aeA64qKqOw+wDAbhw7OIkjWfXKZtPSnIO8ChwZ1W9l2w5UtjqfRvAxmLlSRrLXFM2JzkTeAJ4sqruG9p+CNxQVceH8/rvVdVv7bIdz9mliS18zp7ZIfxB4OjJoA8eBw4MyweAx5YtUtJ05rkafz3wfeAV4MOh+evMztsfAS4D3gRuq6p3d9mWR3ZpYtsd2ecaxo/FsEvTW3gYL+n0YNilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41Mc9cb5cmeSbJ0SSvJrljaL87yVtJDg+Pm6YqsrZ7VI3+kE5X88z1tg/YV1UvJjkXeAG4BfhD4IOq+ubcO1tw+qdt3zRBOOedilraq7ab/mnX+dmr6jhwfFh+P8lR4OJxy5M0tY91zp7kcuBqZjO4Atye5OUkDyU5b+TaJI1o7rAnOQd4FLizqt4D7geuAPYzO/Lfu837NpIcSnJohHolLWiuKZuTnAk8ATxZVfdt8fPLgSeq6qpdtuM5uzSxhadszuy3/0Hg6OagDxfuTroVOLJskZKmM8/V+OuB7wOvAB8OzV8HvsJsCF/AG8BXh4t5O23LI7s0se2O7HMN48di2KXpLTyMl3R6MOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTex6W6q9YNt/TfGfVqS5eWSXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS03MM9fbryb5jyQvJXk1yV8M7ecneSrJa8OzUzZLe9g8c70FOLuqPhhmc/134A7gD4B3q+qeJHcB51XV13bZ1urmmpKaWnj6p5r5YHh55vAo4Gbg4NB+ELhlhDolTWSuc/YkZyQ5DJwAnqqq54CLTs7aOjxfOF2ZkpY1V9ir6pdVtR+4BLguyVXz7iDJRpJDSQ4tWqSk5X2sq/FV9T/A94AbgXeS7AMYnk9s854Hquraqrp2yVolLWGeq/G/keTXh+VfA34X+AHwOHBgWO0A8NhURUpa3jxX4z/P7ALcGcw+HB6pqr9M8mngEeAy4E3gtqp6d5dteTVemth2V+N3DfuYDLs0vYW/epN0ejDsUhOGXWrCsEtNGHapiVVP//Qz4L+H5QuG1+tmHR9lHR/1SavjN7f7wUq/evvIjpNDe+Gv6qzDOrrU4TBeasKwS02sM+wPrHHfm1nHR1nHR502daztnF3SajmMl5pYS9iT3Jjkh0leH+5ftxZJ3kjySpLDq7y5RpKHkpxIcmRT28pv4LlNHXcneWvok8NJblpBHZcmeSbJ0eGmpncM7Svtkx3qWGmfTHaT16pa6YPZv8r+GPgscBbwEvC5Vdcx1PIGcMEa9vtF4BrgyKa2vwbuGpbvAv5qTXXcDfzpivtjH3DNsHwu8CPgc6vukx3qWGmfAAHOGZbPBJ4DfnvZ/ljHkf064PWq+klV/Rz4NrObV7ZRVc8Cp/7v/8pv4LlNHStXVcer6sVh+X3gKHAxK+6THepYqZoZ/Sav6wj7xcBPN70+xho6dFDAd5O8kGRjTTWctJdu4Hl7kpeHYf5K5wNIcjlwNbOj2dr65JQ6YMV9MsVNXtcR9q3+sX5dXwl8oaquAX4f+JMkX1xTHXvJ/cAVwH7gOHDvqnac5BzgUeDOqnpvVfudo46V90ktcZPX7awj7MeASze9vgR4ew11UFVvD88ngO8wO8VYl7lu4Dm1qnpn+EX7EPg7VtQnwwQkjwL/WFX/PDSvvE+2qmNdfTLs+2Pf5HU76wj788CVST6T5Czgy8xuXrlSSc5Ocu7JZeBLwJGd3zWpPXEDz5O/TINbWUGfDLMOPQgcrar7Nv1opX2yXR2r7pPJbvK6qiuMp1xtvInZlc4fA3+2pho+y+ybgJeAV1dZB/Aws+Hg/zIb6fwx8GngaeC14fn8NdXxD8ArwMvDL9e+FdRxPbNTuZeBw8PjplX3yQ51rLRPgM8D/zns7wjw50P7Uv3hX9BJTfgXdFIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmvg/lzZtI/7NwmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004538971115835011, x_l = 3.0, y_l = 25.0, x_t = 2.0, y_t = 25.0.\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader[\"train\"])\n",
    "images, labels, scales = dataiter.next()\n",
    "outputs = net[net_choice](images) \n",
    "\n",
    "net_show(labels, outputs,pos_scale=i_dim-n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25.5487,  6.3102],\n",
       "        [10.4187,  9.8633],\n",
       "        [14.0806, 12.9848],\n",
       "        [ 2.1276, 25.3744]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs *(i_dim - n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17., 23.],\n",
       "        [13., 24.],\n",
       "        [26., 21.],\n",
       "        [ 4., 19.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels *(i_dim - n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005425386596471071\n",
      "0.00017682100587990135\n",
      "0.0004358791629783809\n",
      "0.0004538971115835011\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs)):\n",
    "    print(loss_fn(outputs[i], labels[i]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9438, 0.6781])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = {}\n",
    "net = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetPath(net_choice, epoch, learnrate, original=False):\n",
    "    if original:\n",
    "        return f\"{net_path[net_choice]}.pth\"\n",
    "    return f\"{net_path[net_choice]}_lr_{learnrate}_ep_{epoch}.pth\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"conv\"] = './pixel_finder_conv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "\n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
    "\n",
    "def activation_func(activation):\n",
    "    return  nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    \n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "    \n",
    "    \n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    \"\"\"\n",
    "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )\n",
    "    \n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "class ResNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet layer composed by `n` blocks stacked one after the other\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = ResNetLayer(3, 16, block=ResNetBasicBlock, n=2)\n",
    "        self.fc1 = nn.Linear(32*32*16 , 1024)\n",
    "        self.fc2 = nn.Linear(1024,2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sig(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "net[\"conv\"] = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"linear\"] = './pixel_finder_linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(i_dim*i_dim*3, i_dim*i_dim*3)\n",
    "        self.fc2 = nn.Linear(i_dim*i_dim*3,2)\n",
    "        #self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net[\"linear\"] = LinearNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path[\"linearSig\"] = './pixel_finder_linear_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSigNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearSigNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(i_dim*i_dim*3, i_dim*i_dim*3)\n",
    "        self.fc2 = nn.Linear(i_dim*i_dim*3,2)\n",
    "        #self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "net[\"linearSig\"] = LinearSigNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_choice = \"linearSig\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {\n",
    "    \"learnrate\" : (0.0001, 0.00001),\n",
    "    \"epoch\" : (4,)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "learnrate = 0.00001\n",
    "epoch = 5\n",
    "hyperparameter = {\n",
    "    \"learnrate\" : (learnrate,),\n",
    "    \"epoch\" : (epoch,)}\n",
    "\n",
    "net_choice = \"linearSig\"\n",
    "optimizer[learnrate] = torch.optim.Adam(net[net_choice].parameters(), lr=learnrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, optimization criterion, optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = {}\n",
    "for lr in hyperparameter[\"learnrate\"]:\n",
    "    optimizer[lr] = torch.optim.Adam(net[net_choice].parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output every running_loss_count\n",
    "running_loss_count = 50\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate the net with 5 epochs and a learning rate of 1e-05\n",
      "(Epoch 1, batch 50): 0.6400479120016098\n",
      "(Epoch 1, batch 100): 0.6765033981204033\n",
      "(Epoch 1, batch 150): 0.6344033795595169\n",
      "(Epoch 1, batch 200): 0.6385736167430878\n",
      "(Epoch 1, batch 250): 0.613611376285553\n",
      "(Epoch 1, batch 300): 0.5879561886191368\n",
      "(Epoch 1, batch 350): 0.610289744734764\n",
      "(Epoch 1, batch 400): 0.6248216217756272\n",
      "(Epoch 1, batch 450): 0.5955767711997032\n",
      "(Epoch 1, batch 500): 0.564261546432972\n",
      "(Epoch 2, batch 50): 0.5581617742776871\n",
      "(Epoch 2, batch 100): 0.5493291252851487\n",
      "(Epoch 2, batch 150): 0.5033570399880409\n",
      "(Epoch 2, batch 200): 0.5163902173936367\n",
      "(Epoch 2, batch 250): 0.5209980836510658\n",
      "(Epoch 2, batch 300): 0.5042457789182663\n",
      "(Epoch 2, batch 350): 0.5277198401093482\n",
      "(Epoch 2, batch 400): 0.5229061254858971\n",
      "(Epoch 2, batch 450): 0.48894578114151954\n",
      "(Epoch 2, batch 500): 0.4363142846524715\n",
      "(Epoch 3, batch 50): 0.4273443886637688\n",
      "(Epoch 3, batch 100): 0.4206266738474369\n",
      "(Epoch 3, batch 150): 0.40115339517593385\n",
      "(Epoch 3, batch 200): 0.44673885822296144\n",
      "(Epoch 3, batch 250): 0.37688298016786576\n",
      "(Epoch 3, batch 300): 0.39001990169286727\n",
      "(Epoch 3, batch 350): 0.34646085381507874\n",
      "(Epoch 3, batch 400): 0.32833460450172425\n",
      "(Epoch 3, batch 450): 0.35740744300186633\n",
      "(Epoch 3, batch 500): 0.31204829074442386\n",
      "(Epoch 4, batch 50): 0.2912678428739309\n",
      "(Epoch 4, batch 100): 0.3287264517694712\n",
      "(Epoch 4, batch 150): 0.25062141053378584\n",
      "(Epoch 4, batch 200): 0.28879294633865354\n",
      "(Epoch 4, batch 250): 0.26120386805385354\n",
      "(Epoch 4, batch 300): 0.24387458337470888\n",
      "(Epoch 4, batch 350): 0.1861323631554842\n",
      "(Epoch 4, batch 400): 0.20397111028432846\n",
      "(Epoch 4, batch 450): 0.21941202192567288\n",
      "(Epoch 4, batch 500): 0.18520005155354738\n",
      "(Epoch 5, batch 50): 0.21112001080065965\n",
      "(Epoch 5, batch 100): 0.1722002689912915\n",
      "(Epoch 5, batch 150): 0.1396625316143036\n",
      "(Epoch 5, batch 200): 0.16458408284932374\n",
      "(Epoch 5, batch 250): 0.1551350233075209\n",
      "(Epoch 5, batch 300): 0.13429796658456325\n",
      "(Epoch 5, batch 350): 0.153763440027833\n",
      "(Epoch 5, batch 400): 0.09720059201819822\n",
      "(Epoch 5, batch 450): 0.12125121789053082\n",
      "(Epoch 5, batch 500): 0.10114499870687724\n",
      "(Batch 50): 0.1104393914877437\n",
      "(Batch 100): 0.11269252919591963\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# save starting net\n",
    "torch.save(net[net_choice].state_dict(), getNetPath(net_choice, 0,0, original=True))\n",
    "\n",
    "for num_epoch in hyperparameter[\"epoch\"]:\n",
    "    for learnrate in hyperparameter[\"learnrate\"]:\n",
    "        #load the original net to start from the same parameters\n",
    "        net[net_choice].load_state_dict(torch.load(getNetPath(net_choice, 0,0, original=True)))\n",
    "        net[net_choice].train()\n",
    "        print(f\"Calculate the net with {num_epoch} epochs and a learning rate of {learnrate}\")\n",
    "        for epoch in range(num_epoch):\n",
    "            loss_running = 0.0\n",
    "            metrics[(epoch, learnrate, \"running_loss\")] = []\n",
    "            metrics[(epoch, learnrate, \"validation_loss\")] = []\n",
    "            for i_batch, sample_batched in enumerate(dataloader[\"train\"]):\n",
    "                inputs, labels, _ = sample_batched\n",
    "                \n",
    "                #reset calculated gradients\n",
    "                optimizer[learnrate].zero_grad()\n",
    "                \n",
    "                #calculate the output and loss\n",
    "                outputs = net[net_choice](inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                #backpropagate loss and optimize parameter\n",
    "                loss.backward()\n",
    "                optimizer[learnrate].step()\n",
    "                \n",
    "                #track loss\n",
    "                loss_running += loss.item()\n",
    "                if i_batch % running_loss_count == running_loss_count -1:\n",
    "                    print(f\"(Epoch {epoch + 1}, batch {i_batch + 1}): {loss_running/running_loss_count}\")\n",
    "                    metrics[(epoch, learnrate, \"running_loss\")].append(loss_running)\n",
    "                    loss_running = 0.0\n",
    "            #save the trained net after each epoch\n",
    "            torch.save({\"net_state_dict\":net[net_choice].state_dict(),\n",
    "                   \"optimizer_state_dict\":optimizer[learnrate].state_dict(),\n",
    "                   \"epoch\" : epoch}, getNetPath(net_choice, epoch,learnrate))\n",
    "        #torch.save(net[net_choice].state_dict(), getNetPath(net_choice, epoch,learnrate))\n",
    "        \n",
    "        #do the validation\n",
    "        net[net_choice].eval()\n",
    "        with torch.no_grad():\n",
    "            loss_running = 0.0\n",
    "            for i_batch, sample_batched in enumerate(dataloader[\"validate\"]):\n",
    "                inputs, labels, _ = sample_batched\n",
    "                \n",
    "                #calculate the output and loss\n",
    "                outputs = net[net_choice](inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                #track loss\n",
    "                loss_running += loss.item()\n",
    "                if i_batch % running_loss_count == running_loss_count -1:\n",
    "                    print(f\"(Batch {i_batch + 1}): {loss_running/running_loss_count}\")\n",
    "                    metrics[(epoch, learnrate, \"validation_loss\")].append(loss_running)\n",
    "                    loss_running = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the net as basis for the next round\n",
    "torch.save(net[net_choice].state_dict(), getNetPath(net_choice, 0,0, original=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "learnrate = 0.00001\n",
    "epoch = 2\n",
    "hyperparameter = {\n",
    "    \"learnrate\" : (learnrate,),\n",
    "    \"epoch\" : (epoch,)}\n",
    "\n",
    "net_choice = \"linearSig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = {}\n",
    "#print(getNetPath(net_choice, epoch, learnrate))\n",
    "checkpoint = torch.load(getNetPath(net_choice, epoch, learnrate))\n",
    "optimizer[learnrate] = torch.optim.Adam(net[net_choice].parameters(), lr=learnrate)\n",
    "optimizer[learnrate].load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "net[net_choice].load_state_dict(checkpoint[\"net_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x4096 and 3072x3072)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c50ccb8f6dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet_choice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-da80211702d9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x4096 and 3072x3072)"
     ]
    }
   ],
   "source": [
    "summary(net[net_choice], input_size=(4,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSigNet(\n",
       "  (fc1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (fc2): Linear(in_features=3072, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[net_choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(dataset):\n",
    "    net[net_choice].eval()\n",
    "    bias = 0.0\n",
    "    with torch.no_grad():\n",
    "        #loss_running = 0.0\n",
    "        n_total = 0\n",
    "        for i_batch, sample_batched in enumerate(dataloader[dataset]):\n",
    "            inputs, labels, _ = sample_batched\n",
    "\n",
    "            #calculate the output and loss\n",
    "            outputs = net[net_choice](inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            #track loss\n",
    "            #loss_running += loss.item()\n",
    "            bias += loss.item()\n",
    "            n_total += 1\n",
    "            #if i_batch % running_loss_count == running_loss_count -1:\n",
    "                #print(f\"(Batch {i_batch + 1}): {loss_running/running_loss_count}\")\n",
    "                #metrics[(num_epoch, learnrate, f\"{dataset}_loss\")].append(loss_running)\n",
    "                #loss_running = 0.0\n",
    "        bias /= n_total\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.0007012143000938522, Validation: 0.02302990819979459, Test: 0.020292832299135626\n"
     ]
    }
   ],
   "source": [
    "#Linear net\n",
    "train_score = score(\"train\")\n",
    "validation_score = score(\"validate\")\n",
    "test_score = score(\"test\")\n",
    "print(f\"Training: {train_score}, Validation: {validation_score}, Test: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.0022092224386069574, Validation: 0.008320434645749629, Test: 0.009907132481224835\n"
     ]
    }
   ],
   "source": [
    "#LinearSig net\n",
    "train_score = score(\"train\")\n",
    "validation_score = score(\"validate\")\n",
    "test_score = score(\"test\")\n",
    "print(f\"Training: {train_score}, Validation: {validation_score}, Test: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, learnrate, dataset, loss in metrics.items():\n",
    "    if dataset == \"validation_loss\":\n",
    "        plt.plot(range(len(loss))*running_loss_count, loss,label=f\"lr: {learnrate}, epochs:{epochs}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
